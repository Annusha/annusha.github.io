<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Anna Kukleva</title>
  
  <meta name="author" content="Anna Kukleva">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" type="image/png" href="images/Blue_Jays.png">
  <title>Anna Kukleva</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>

  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-113195086-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-113195086-1'); 
</script>

<style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #2d59eb;
      text-decoration: none;
    }
    b {
      color: #000000;
      text-decoration: none;
    }
    c {
      color: #0BDA51;
      text-decoration: none;
    }
    d {
      color: #FFA500;
      text-decoration: none;
    }
    a:focus,
    a:hover {
      color: #af19bf;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px
      background-image: "images/jose/bg.png";
       /*background-color: #fffff;*/
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 24px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14.5px;
      font-weight: 600
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 34px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      background-color: #CA7FD4;
    }
  </style>


</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Anna Kukleva</name>
              </p>
              <p style="text-align:justify">
              I’m  Anna Kukleva, a PhD student at <a href=“https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/“>Computer Vision and Machine Learning department</a> at <a href=“https://www.mpi-inf.mpg.de/home/“>Max Plank Institute for Informatics</a> supervised by <a href=“https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele/“>Bernt Schiele</a>. My research involves close collaborations with <a href=“https://hildekuehne.github.io/“>Hilde Kuehne</a> (Bonn), and <a href=“https://chrirupp.github.io/“>Christian Rupprecht</a> (Oxford). During my PhD, I’ve visited Meta FAIR and FRL labs as research intern. Particularly, in Nimble XR Input team at FRL, we were working on egocentric videos with <a href=“https://scholar.google.com/citations?user=-juoweoAAAAJ&hl=en>Fadime Sener</a>. Prior to my PhD, I had the opportunity to work in <a href=“https://www.di.ens.fr/willow/“>WILLOW team</a> at Inria Paris on  multi-modal understanding of social human behaviour with <a href=“https://makarandtapaswi.github.io/“>Makarand Tapaswi</a> and <a href=“https://www.di.ens.fr/~laptev/“>Ivan Laptev</a>.  During my master, I’ve been working on unsupervised video segmentation in Uni Bonn in the lab of <a href=“https://pages.iai.uni-bonn.de/gall_juergen/“>Jürgen Gall</a>.
              </p>
              <p style="text-align:justify">
              My research focuses on image and multi-modal video recognition, with a specific interest in learning representations through self-supervised, semi-supervised, and rarely fully-supervised methods.  My focus extends to exploring the transferability of these methods to few-shot and open-set generalization scenarios.
              </p>
              </p>
              <p style="text-align:center">
                <a href="mailto:akukleva@mpi-inf.mpg.de">Email</a> &nbsp/&nbsp
                <a href="data/November_2023.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=eLZ_clAAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/Annusha">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/annakukleva/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:0.75%;width:35%;max-width:35%">
              <a href="images/JonBarron.jpg"><img style="width:90%;max-width:90%" alt="profile photo" src="images/Anna3.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>



        <!-- News -->
<!--        <hr>-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
              <heading>News</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="padding:10px;width:100%;border:0px;border-spacing:3px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <!-- ITEM -->
        <tr>
            <td>
              <p style="color:black; display:inline">&#x2022; Nov '23 &nbsp;</p>
            </td>
            <td>
               Top reviewer at NeurIPS 2023
            </td>
          </tr>
          <!-- ITEM -->
        <tr>
            <td>
              <p style="color:black; display:inline">&#x2022; Aug '23 &nbsp;</p>
            </td>
            <td>
               Serve as area chair for WACV 2024
            </td>
          </tr>
          <!-- ITEM -->
        <tr>
            <td>
              <p style="color:black; display:inline">&#x2022; Jul '23 &nbsp;</p>
            </td>
            <td>
               3 papers accepted at ICCV 2023
            </td>
          </tr>
          <!-- ITEM -->
        <tr>
            <td>
              <p style="color:black; display:inline">&#x2022; May '23 &nbsp;</p>
            </td>
            <td>
               Joined Meta FRL as a research intern. Working with <a href=“https://scholar.google.com/citations?user=-juoweoAAAAJ&hl=en>Fadime Sener</a>
            </td>
          </tr>
          <!-- ITEM -->
          <tr>
            <td>
              <p style="color:black; display:inline">&#x2022; Feb '23 &nbsp;</p>
            </td>
            <td>
              Top reviewer at AISTAT 2023
            </td>
          </tr>
          <!-- ITEM -->
          <tr>
            <td>
              <p style="color:black; display:inline">&#x2022; Jan '23 &nbsp;</p>
            </td>
            <td>
              1 paper accepted at ICLR 2023
            </td>
          </tr>
          <!-- ITEM -->

          </tbody>
        </table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a id="news"><heading>Publications</heading></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
            <td style="padding:5px;width:40%;vertical-align:middle">
              <div style="text-align: center">
              <img src="images/howtocaption_2023/featured.png" alt="HowToCaption" width="240" height="100" class="center">
              </div>
            </td>
            <td width="75%" valign="middle">
                <br>
                 <a href="https://arxiv.org/pdf/2310.04900.pdf"> <papertitle>HowToCaption: Prompting LLMs to Transform Video Annotations at Scale</papertitle></a>
            <br>
            <a href="https://ninatu.github.io/">Nina Shvetsova*</a>, <b>Anna Kukleva*</b>, <a href="https://xudonghong.me/">Xudong Hong</a>, <a href="https://chrirupp.github.io/">Christian Rupprecht</a>, <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>, <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>
            <br>
            (*equal contribution)
            <br>
            <em>ArXiv, 2023</em>

        <p> <a href="https://arxiv.org/pdf/2310.04900.pdf">Paper</a> | <a href="https://github.com/ninatu/howtocaption">Code</a>
            <br><br>
            </td>
          </tr>


          <tr>
            <td style="padding:5px;width:40%;vertical-align:middle">
              <div style="text-align: center">
              <img src="images/iccv-2023_in_style/featured.png" alt="InStyle" width="240" height="100" class="center">
              </div>
            </td>
            <td width="75%" valign="middle">
                <br>
                 <a href=""> <papertitle>In-Style: Bridging Text and Uncurated Videos with Style Transfer for Text-Video Retrieval</papertitle></a>
            <br>
            <a href="https://ninatu.github.io/">Nina Shvetsova*</a>, <b>Anna Kukleva*</b>, <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>, <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>
            <br>
                        (*equal contribution)
            <br>
            <em>ICCV, 2023</em>

        <p> <a href="https://arxiv.org/pdf/2309.08928.pdf">Paper</a> | <a href="https://github.com/ninatu/in_style">Code</a>
            <br><br>
            </td>
          </tr>



          <tr>
            <td style="padding:5px;width:40%;vertical-align:middle">
              <div style="text-align: center">
              <img src="images/iccv-2023_open_set/featured.png" alt="SBB" width="200" height="100" class="center">
              </div>
            </td>
            <td width="75%" valign="middle">
                <br>
                 <a href=""> <papertitle>SSB: Simple but Strong Baseline for Boosting Performance of Open-Set Semi-Supervised Learning</papertitle></a>
            <br>
            <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/yue-fan">Yue Fan</a>, <b>Anna Kukleva</b>, <a href="https://vas.mpi-inf.mpg.de/dengxin/">Dengxin Dai</a>, <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>
            <br>
            <em>ICCV, 2023</em>

        <p> <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_SSB_Simple_but_Strong_Baseline_for_Boosting_Performance_of_Open-Set_ICCV_2023_paper.pdf">Paper</a> | <a href="https://github.com/YUE-FAN/SSB">Code</a>
            <br><br>
            </td>
          </tr>


          <tr>
            <td style="padding:5px;width:40%;vertical-align:middle">
              <div style="text-align: center">
              <img src="images/iccv-2023_sorting/featured.png" alt="Sorting" width="160" height="100" class="center">
              </div>
            </td>
            <td width="75%" valign="middle">
                <br>
                 <a href=""> <papertitle>Learning by Sorting: Self-supervised Learning with Group Ordering Constraints</papertitle></a>
            <br>
            <a href="https://ninatu.github.io/">Nina Shvetsova</a>, <a href="https://petersen.ai/">Felix Petersen</a>, <b>Anna Kukleva</b>, <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>, <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>
            <br>
            <em>ICCV, 2023</em>

        <p> <a href="https://arxiv.org/abs/2301.02009">Paper</a>
            <br><br>
            </td>
          </tr>

          <tr>
            <td style="padding:5px;width:40%;vertical-align:middle">
              <div style="text-align: center">
              <img src="images/dagm21.png" alt="Rev" width="160" height="80" class="center">
              </div>
            </td>
            <td width="75%" valign="middle">
                <br>
                 <a href=""> <papertitle>Revisiting Consistency Regularization for Semi-Supervised Learning</papertitle></a>
            <br>
             <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/yue-fan">Yue Fan</a>, <b>Anna Kukleva</b>,  <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>
            <br>
            <em>IJCV, 2023</em>

                <p> <a href="https://arxiv.org/pdf/2112.05825.pdf">Paper</a>
            <br><br>
            </td>
          </tr>



          <tr>
            <td style="padding:5px;width:40%;vertical-align:middle">
              <div style="text-align: center">
              <img src="images/iclr_2023/featured.png" alt="Temperature" width="230" height="100" class="center">
              </div>
            </td>
            <td width="75%" valign="middle">
                <br>
                 <a href=""> <papertitle>Temperature Schedules for self-supervised contrastive methods on long-tail data</papertitle></a>
            <br>
            <b>Anna Kukleva*</b>, <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/moritz-boehle">Moritz Boehle*</a>, <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>, <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>, <a href="https://chrirupp.github.io/">Christian Rupprecht</a>
            <br>
                        (*equal contribution)
            <br>
            <em>ICLR, 2023</em>

        <p> <a href="https://openreview.net/pdf?id=ejHUr4nfHhD">Paper</a> | <a href="https://github.com/Annusha/temperature_schedules">Code</a>
            <br><br>
            </td>
          </tr>

          <tr>
            <td style="padding:5px;width:40%;vertical-align:middle">
              <div style="text-align: center">
              <img src="images/eccvw-2022/featured.png" alt="Oops" width="180" height="100" class="center">
              </div>
            </td>
            <td width="75%" valign="middle">
                <br>
                 <a href=""> <papertitle>Leveraging Self-Supervised Training for Unintentional Action Recognition</papertitle></a>
            <br>
            <a href="https://scholar.google.com/citations?user=vdRxulMAAAAJ&hl=en">Enea Duka*</a>, <b>Anna Kukleva*</b>, <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>
            <br>
            <em>ECCVW, 2022</em>

        <p> <a href="https://arxiv.org/pdf/2209.11870.pdf">Paper</a> | <a href="https://github.com/dukaenea/unintentional_actions">Code</a>
            <br><br>
            </td>
          </tr>


          <tr>
            <td style="padding:5px;width:40%;vertical-align:middle">
              <div style="text-align: center">
              <img src="images/eccv-2022/featured.png" alt="CycDA" width="160" height="100" class="center">
              </div>
            </td>
            <td width="75%" valign="middle">
                <br>
                 <a href=""> <papertitle>CycDA: Unsupervised Cycle Domain Adaptation from Image to Video</papertitle></a>
            <br>
            <a href="https://wlin-at.github.io/">Wei Lin</a>, <b>Anna Kukleva</b>, <a href="https://www.researchgate.net/profile/Kunyang-Sun"> Kunyang Sun</a>, <a href="https://snototter.github.io/research/">Horst Possegger</a>, <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>, <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>
            <br>
            <em>ECCV, 2022</em>

        <p> <a href="https://arxiv.org/pdf/2203.16244.pdf">Paper</a>
            <br><br>
            </td>
          </tr>

            <tr>
            <td style="padding:5px;width:40%;vertical-align:middle">
              <div style="text-align: center">
              <img src="images/TAEC.png" alt="taec" width="240" height="100" class="center">
              </div>
            </td>
            <td width="75%" valign="middle">
                <br>
                 <a href=""> <papertitle>TAEC: Unsupervised Action Segmentation with Temporal-Aware Embedding and Clustering</papertitle></a>
            <br>
             <a href="https://wlin-at.github.io/">Wei Lin</a>, <b>Anna Kukleva</b>, <a href="https://snototter.github.io/research/">Horst Possegger</a>, <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>, <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof">Horst Bischof</a>
            <br>
            <em>CEUR Workshop, 2023 </em>

        <p> <a href="https://arxiv.org/abs/2303.05166">Paper</a> 
            <br><br>
            </td>
          </tr>


          <tr>
            <td style="padding:5px;width:40%;vertical-align:middle">
              <div style="text-align: center">
              <img src="images/cvpr-2022/featured.png" alt="CoSSL" width="180" height="100" class="center">
              </div>
            </td>
            <td width="75%" valign="middle">
                <br>
                 <a href=""> <papertitle>CoSSL: Co-Learning of Representation and Classifier for Imbalanced Semi-Supervised Learning</papertitle></a>
            <br>
            <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/yue-fan">Yue Fan</a>, <a href="https://vas.mpi-inf.mpg.de/dengxin/">Dengxin Dai</a>, <b>Anna Kukleva</b>, <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele">Bernt Schiele</a>
            <br>
            <em>CVPR, 2022</em>

        <p> <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_CoSSL_Co-Learning_of_Representation_and_Classifier_for_Imbalanced_Semi-Supervised_Learning_CVPR_2022_paper.pdf">Paper</a> | <a href="https://github.com/YUE-FAN/CoSSL">Code</a>
            <br><br>
            </td>
          </tr>


          <tr>
            <td style="padding:5px;width:40%;vertical-align:middle">
              <div style="text-align: center">
              <img src="images/iccv21.png" alt="FSL" width="180" height="100" class="center">
              </div>
            </td>
            <td width="75%" valign="middle">
                <br>
                 <a href=""> <papertitle>Generalized and Incremental Few-Shot Learning by Explicit Learning and Calibration Without Forgetting</papertitle></a>
            <br>
             <b>Anna Kukleva</b>, Hilde Kuehne,  Bernt Schiele
            <br>
            <em>ICCV, 2021</em>

        <p> <a href="https://arxiv.org/pdf/2108.08165.pdf">Paper</a> | <a href="https://github.com/Annusha/LCwoF">Code</a>
            <br><br>
            </td>
          </tr>


          <tr>
            <td style="padding:5px;width:40%;vertical-align:middle">
              <div style="text-align: center">
              <img src="images/wacv21.png" alt="wacv21" width="180" height="100" class="center">
              </div>
            </td>
            <td width="75%" valign="middle">
                <br>
                 <a href=""> <papertitle>Joint Visual-Temporal Embedding for Unsupervised Learning of Actions in Untrimmed Sequences</papertitle></a>
            <br>
                <a href="https://www.rvidal.me/">Rosaura G. VidalMata</a>, <a href="https://www.wjscheirer.com/">Walter J. Scheirer</a>, <b>Anna Kukleva</b>, <a href="https://mitibmwatsonailab.mit.edu/people/david-cox/">David Cox</a>, <a href="https://hildekuehne.github.io/">Hilde Kuehne</a>
            <br>
            <em>WACV, 2021</em>

        <p> <a href="https://openaccess.thecvf.com/content/WACV2021/papers/VidalMata_Joint_Visual-Temporal_Embedding_for_Unsupervised_Learning_of_Actions_in_Untrimmed_WACV_2021_paper.pdf">Paper</a>
            <br><br>
            </td>
          </tr>


          <tr>
            <td style="padding:5px;width:40%;vertical-align:middle">
              <div style="text-align: center">
              <img src="images/cvpr20.jpg" alt="movies" width="180" height="100" class="center">
              </div>
            </td>
            <td width="75%" valign="middle">
                <br>
                 <a href=""> <papertitle>Learning Interactions and Relationships between Movie Characters</papertitle></a>
            <br>
             <b>Anna Kukleva</b>, <a href="https://makarandtapaswi.github.io/"> Makarand Tapaswi</a>,  <a href="https://www.di.ens.fr/~laptev/"> Ivan Laptev</a>
            <br>
            <em>CVPR, 2020 <b>(Oral)</b></em>

        <p> <a href="https://arxiv.org/pdf/2003.13158.pdf">Paper</a> | <a href="https://annusha.github.io/LIReC/">Code</a>
            <br><br>
            </td>
          </tr>



          <tr>
            <td style="padding:5px;width:40%;vertical-align:middle">
              <div style="text-align: center">
              <img src="images/robotics.png" alt="robo" width="180" height="100" class="center">
              </div>
            </td>
            <td width="75%" valign="middle">
                <br>
                 <a href=""> <papertitle>Utilizing Temporal Information in Deep Convolutional Network for Efficient Soccer Ball Detection and Tracking</papertitle></a>
            <br>
             <b>Anna Kukleva*</b>, <a href="https://mdasifkhan.github.io/"> Mohammad Asif Khan*</a>, <a href="https://www.ais.uni-bonn.de/~hfarazi/"> Hafez Farazi</a>, <a href="https://www.ais.uni-bonn.de/behnke/">Sven Behnke</a>
            <br>
                            (*equal contribution)
            <br>
            <em>RoboCup 2019 <b>(Oral)</b></em>

        <p> <a href="https://2019.robocup.org/downloads/program/KuklevaEtAl2019.pdf">Paper</a> | <a href="https://github.com/AIS-Bonn/TemporalBallDetection">Code</a>
            <br><br>
            </td>
          </tr>


          <tr>
            <td style="padding:5px;width:40%;vertical-align:middle">
              <div style="text-align: center">
              <img src="images/cvpr19.png" alt="cet" width="240" height="100" class="center">
              </div>
            </td>
            <td width="75%" valign="middle">
                <br>
                 <a href=""> <papertitle>Unsupervised Learning of Action Classes with Continuous Temporal Embedding</papertitle></a>
            <br>
             <b>Anna Kukleva*</b>, <a href="https://hildekuehne.github.io/">Hilde Kuehne*</a>,  <a href=“https://scholar.google.com/citations?user=-juoweoAAAAJ&hl=en>Fadime Sener</a>, <a href="https://pages.iai.uni-bonn.de/gall_juergen/">Jürgen Gall</a>
            <br>
                (*equal contribution)
            <br>
            <em>CVPR, 2019 </em>

        <p> <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Kukleva_Unsupervised_Learning_of_Action_Classes_With_Continuous_Temporal_Embedding_CVPR_2019_paper.pdf">Paper</a> | <a href="https://github.com/Annusha/unsup_temp_embed">Code</a>
            </td>
          </tr>



        </tbody></table>

        
        <br>
        <table width="100%" align="center" border="0" cellpadding="0">
          <tr style="padding:0px">
            <td width="100%" valign="middle">
              <a id="news"><heading>Talks</heading></a>
            </td>
          </tr>
          <tr>
            <td width="75%" valign="center">
              <p>
              <ul>
                <li>
                  01/2022: Talk at <a href="https://www.youtube.com/watch?v=i6ZbnnKIACI">Compuer Vision Talks</a>, Virtual
                </li>
                <li>
                  12/2020: Talk at <a href="https://www.youtube.com/watch?v=TixJu8p9QZQ"> 6th Christmas Colloquium on Computer Vision 2020</a>, Samsung AI Center Moscow, Virtual
                </li>
              <li>
                  08/2020: Talk at <a href="https://www.notion.so/dlcv/Welcome-to-the-Deep-Learning-Computer-Vision-Practitioners-community-1acb5d6d9e6f461f84f6f0d88e90d608">DLCV Practioner’s Evening</a>, Virtual
                </li>
              <li>
                  01/2020: Talk at <a href="http://www.cs.cmu.edu/~abhinavg/"> Abhinav Gupta’s</a> group at CMU in Pittsburgh, USA
                </li>
              <li>
                  11/2019: Talk at <a href="https://www.di.ens.fr/willow/events/workshop26nov2019/"> WILLOW-ENPC-Berkeley Workshop on Vision and Robotics</a> in Paris, France
                </li>
              <li>
                  09/2019: Poster at <a href="http://people.cs.bris.ac.uk/~damen/bmva_symposium_2019/"> BMVA symposium on Video Understanding</a> in London, UK
                </li>
              <li>
                  06/2019: Poster at <a href="https://wicvworkshop.github.io/CVPR2019/index.html"> WiCV workshop</a> in conjunction with CVPR 2019 in Long Beach, USA
                </li>
              </ul>
              </p>
            </td>
          </tr>
        </table>


        <br>
        <table width="100%" align="center" border="0" cellpadding="0">
          <tr style="padding:0px">
            <td width="100%" valign="middle">
              <a id="news"><heading>Academic</heading></a>
            </td>
          </tr>
          <tr>
            <td width="75%" valign="center">
              <p>
              <ul>
                <li>
                  Area Chair: WACV24
                </li>
                <li>
                    Top Reviewer: AISTAT23, NeurIPS23
                </li>
                <li>
                  Reviewer: CVPR21-23, ICCV21-23, ECCV22, AISTAT23, NeurIPS23, WACV21-22, PAMI, IJCV, TMM, ACMMM21
                </li>
              <li>
                  07/2021: <a href="https://www.informatik.uni-bonn.de/de/gleichstellung/talents"> Grace-Hopper-Award</a> (Master Thesis Award), Uni Bonn
                </li>
              <li>
                  ECCV 2020: Coorganizing the <a href="https://sites.google.com/view/wicvworkshop-eccv2020/home"> WiCV workshop</a>, Virtual
                </li>
              </ul>
              </p>
            </td>
          </tr>
        </table>


				

      
					
				
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <br>
                Stolen from <a href="https://jonbarron.info/">Jon Barron</a>. Big thanks! 
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
